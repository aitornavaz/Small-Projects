{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    " # Trabajo final\n",
    "###### Aitor Uranga e Igor Vons\n",
    "El código está dividido en 3 secciones. Estas a su vez en varias partes.\n",
    "\n",
    "La [primera sección](#S1) contiene todas las declaraciones de las funciones. Tiene 5 partes:\n",
    "- En la [1](#S1P1), se declaran las funciones para implementar los métodos de extracción de características expuestos en la primera parte de la guía.\n",
    "- En la [2](#S1P2), se declaran las que hacen falta para implementar la segunda.\n",
    "- En la [3](#S1P3) están dos funciones adicionales usadas para poder dividir las imágenes en un mismo número de celdas sin tener que recurrir a deformar las imágenes a un tamaño determinado para poder tener un vector de características de igual longitud para todas la imágenes.\n",
    "- La [4](#S1P4) ofrece una agrupación de las anteriores, así como las funciones necesarias para tratar, cargar y combinar datasets\n",
    "- La [5](#S1P5) tiene la declaración de las funciones usadas para generar, almacenar y cargar datasets ya convertidos a vectores de características. Así se consigue realizar pruebas de manera más ágil, porque la extracción de características es un cómputo bastante costoso.\n",
    "\n",
    "La [segunda sección](#S2) ejecuta el código necesario para estandarizar las imágenes y que encajen para ser divididas en un número fijo de celdas:\n",
    "- En la [parte 1](#S2P1) se obtienen los tamaños de las celdas en las que se dividirán las imágenes, así como su disposición y se recortan los bordes para dejar solo una imagen del tamaño correcto. Estas imágenes se almacenan en directorios similares a los originales, añadiendo el número de celdas a las que se las ha ajustado al final.\n",
    "- En la [2](#S2P2), se almacenan las imágenes de entrenamiento y evaluación, así como sus tamaños de celda en un diccionario que se vaya a usar de referencia.\n",
    "- En la [3](#S2P3), mediante la combinación de distintos parámetros posibles, generamos un conjunto de datos ya vectorizados y los almacenamos en archivos .csv para poder posteriormente cargarlos más rápidamente para realizar pruebas.\n",
    "\n",
    "La [tercera sección](#S3) es en la que se realiza el entrenamiento y evaluación de diversos modelos que podemos encontrar en la librería de 'sklearn'.\n",
    "- En la [parte 1](#S3P1) se declaran funciones con las que manejar los clasificadores a probar. Esto es para poder hallar más fácilmente la combinación de parámetros usados en la extracción y los usados para inicializar el clasificador en sí.\n",
    "- En la [2](#S3P2) ejecutamos un bucle que iterara sobre los parámetros usados en las extracciones de características anteriores. Crea un ranking de modelos en base a la precisión de predicciones en el conjunto de test.\n",
    "- En la [3](#S3P3) podemos finalmente probar el desempeño del modelo que elijamos a partir de los datos obtenidos en el código anterior sobre el dataset principal de 500 imágenes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <a name=\"S1\"></a>Sección 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "import imageio.v3 as imageio\n",
    "import sys\n",
    "from skimage.color import rgb2gray\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. <a name=\"S1P1\"></a>Extracción de características 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def uniform_transition_bins():\n",
    "    \"\"\"\n",
    "    Comprueba que secuencias binarias de longitud 8 tienen dos o menos transiciones de 0 a 1 o de 1 a 0.\n",
    "    :return:\n",
    "        ndarray sequences: Lista numpy con True para las posiciones que no tengan transiciones de longitud 2 o más y False en caso contrario\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializar una lista para almacenar las secuencias\n",
    "    sequences = []\n",
    "    # Iterar sobre todas las secuencias binarias de 8 bits posibles\n",
    "    for i in range(2**8):\n",
    "        # Convertir el entero a una cadena binaria\n",
    "        sequence = format(i, '08b')\n",
    "\n",
    "        # Contar el número de transiciones de 0 a 1 o de 1 a 0\n",
    "        transitions = 0\n",
    "        for j in range(7):\n",
    "            if sequence[j] != sequence[j+1]:\n",
    "                transitions += 1\n",
    "\n",
    "        # Si hay más de dos transiciones, considerarlo una transición no uniforme\n",
    "        if transitions > 2:\n",
    "            sequences.append(False)\n",
    "        else:\n",
    "            sequences.append(True)\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "    return sequences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def cell_to_columns(cell, n, m, color=False):\n",
    "    \"\"\"\n",
    "    Convierte una imagen en una matriz de columnas, donde cada una es el binario obtenido de la celda que rodea cada pixel.\n",
    "\n",
    "    :param ndarray cell: Una imagen.\n",
    "    :param int n: Tamaño vertical de la celda.\n",
    "    :param int m: Tamaño horizontal de la celda.\n",
    "    :param bool color: Indica si la imagen es rgb o escala de grises.\n",
    "\n",
    "    :return:\n",
    "        ndarray im2: Una matriz columnas de 8 elementos binarios.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtener el número de filas y columnas de la imagen\n",
    "    filas, columnas = cell.shape[0], cell.shape[1]\n",
    "    a, b = 1, 1\n",
    "\n",
    "    # Inicializar la matriz de características de celdas binarias\n",
    "    img2 = np.zeros((n*m, (filas-2)*(columnas-2)))\n",
    "\n",
    "    # Iterar sobre cada celda de la imagen\n",
    "    aux = 0\n",
    "    for i in range(1, filas-1):\n",
    "        for j in range(1, columnas-1):\n",
    "            # Obtener el valor binario de la celda\n",
    "            if color:\n",
    "                img2[:, aux] = ((cell[i-a:i+a+1, j-b:j+b+1].mean(axis = 2))>(cell[i,j].mean())).flatten()\n",
    "            else:\n",
    "                img2[:, aux] = (cell[i - a:i + a + 1, j - b:j + b + 1] > cell[i, j]).flatten()\n",
    "\n",
    "            # Reordenar los valores binarios para colocarlos en sentido horario\n",
    "            hardcoded_indx =[1,2,5,8,7,6,3,0,4]\n",
    "            img2[:, aux] = img2[:, aux][hardcoded_indx]\n",
    "\n",
    "            aux += 1\n",
    "    # Eliminamos última fila porque es el elemento central y solo queremos 8 bits\n",
    "    img2 = img2[:-1,:]\n",
    "\n",
    "    return img2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_cell_histogram(cell, uniform_transitions=None):\n",
    "    \"\"\"\n",
    "    Obtiene las características de una celda en una imagen binaria.\n",
    "\n",
    "    :param ndarray cell: Una celda de la imagen previeamente transformada por cell_to_columns.\n",
    "    :param ndarray uniform_transitions: Una lista opcional de booleanos indicando las posiciones del histograma que no comprimir en uno.\n",
    "\n",
    "    :return: Un vector de características de la celda.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convertir las columnas de 8 elementos binarios (0 o 1) en numeros\n",
    "    vec = np.packbits(cell, axis = 0)\n",
    "\n",
    "    # Calcular el histograma de la matriz empaquetada\n",
    "    h = cv2.calcHist([vec],[0],None,[256],[0,256]).flatten()\n",
    "\n",
    "    # Si se proporcionan una lista de valores uniformes, insertar el agragado de transiciones no uniformes al principio del histograma\n",
    "    if uniform_transitions is not None:\n",
    "        not_uniform = h[(uniform_transitions == False)].sum()\n",
    "        h = np.insert(h[uniform_transitions], 0, not_uniform)\n",
    "\n",
    "    return h"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_image_characteristics_vector_1(img, size, version='v1'):\n",
    "    \"\"\"\n",
    "    Extrae el vector de características de una imagen.\n",
    "\n",
    "    :param ndarray img: Una imagen en blanco y negro.\n",
    "    :param int size: El tamaño del lado de las celdas en las que dividir la imagen.\n",
    "    :param version: v1 es la version de la funcion que no aplica la discriminacion por transiciones uniformes o no en el histograma.\n",
    "                    v2 si aplica esta diferenciacion.\n",
    "\n",
    "    :return: Un vector de características de la imagen.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializar la matriz de características\n",
    "    v_caracteristics = np.array([])\n",
    "\n",
    "    #Determina si la imagen es a color o no\n",
    "    color = len(img.shape) > 2\n",
    "\n",
    "    if version == 'v2':\n",
    "        # Obtener la secuencia de transiciónes uniformes\n",
    "        uniform_transitions = uniform_transition_bins()\n",
    "\n",
    "    # Añadir bordes a la imagen\n",
    "    img = cv2.copyMakeBorder(img, 1, 1, 1, 1, cv2.BORDER_REPLICATE)\n",
    "\n",
    "    # Iterar sobre cada celda de la imagen\n",
    "    for i in range(0, img.shape[0], size):\n",
    "        for j in range(0, img.shape[1], size):\n",
    "            # Obtener el vector de características de la celda\n",
    "            img2 = np.uint8(cell_to_columns(img[i:i + size + 2, j:j + size + 2], 3, 3, color=color))\n",
    "            if version == 'v2':\n",
    "                h = (get_cell_histogram(img2, uniform_transitions))\n",
    "            else:\n",
    "                h = (get_cell_histogram(img2))\n",
    "\n",
    "            # Añadir las características de la celda al vector de características de la imagen\n",
    "            v_caracteristics = np.concatenate((v_caracteristics,h))\n",
    "\n",
    "    return v_caracteristics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <a name=\"S1P2\"></a>2. Extracción de caracteristícas 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def apply_filter(image, mask):\n",
    "    \"\"\"\n",
    "    Aplica un filtro a la imagen dada utilizando la máscara especificada.\n",
    "\n",
    "    :param ndarray image: La imagen a la que se aplicará el filtro.\n",
    "    :param ndarray mask: La máscara que se utilizará para aplicar el filtro.\n",
    "\n",
    "    :return:\n",
    "        ndarray img: La imagen filtrada.\n",
    "    \"\"\"\n",
    "    # Hacer una copia de la imagen y convertirla en un array de punto flotante\n",
    "    img = np.copy(np.float32(image))\n",
    "\n",
    "    # Obtener el tamaño de la máscara y calcular la distancia del centro al borde\n",
    "    ni, nj = mask.shape\n",
    "    mi, mj = ni//2, nj//2\n",
    "\n",
    "    # Añadir un borde a la imagen utilizando el tamaño de la mitad de la máscara como tamaño del borde\n",
    "    image_padded = cv2.copyMakeBorder(img, mi, mi, mj, mj, cv2.BORDER_REPLICATE)\n",
    "\n",
    "    # Recorrer todos los píxeles de la imagen\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Aplicar la convolución al píxel actual multiplicando la máscara\n",
    "            # con la región correspondiente de la imagen (con el borde añadido)\n",
    "            # y sumando los valores resultantes\n",
    "            img[i, j] = (image_padded[i:i+ni, j:j+nj] * mask).sum()\n",
    "\n",
    "    # Devolver la imagen modificada\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def gradient(img, grad_type='prewitt'):\n",
    "    \"\"\"\n",
    "    Calcula el gradiente de una imagen utilizando los filtros de Prewitt o Sobel.\n",
    "\n",
    "    :param ndarray img: Imagen de entrada.\n",
    "    :param str grad_type: Tipo de gradiente a utilizar ('prewitt' o 'sobel').\n",
    "\n",
    "    :return:\n",
    "        ndarray e: Magnitud del gradiente.\n",
    "        ndarray phi: Dirección del gradiente.\n",
    "    \"\"\"\n",
    "    # Convierte la imagen a un array numpy de float32\n",
    "    im = np.float32(img)\n",
    "\n",
    "    # Define los filtros de gradiente\n",
    "    if grad_type=='prewitt':\n",
    "        # Filtros de gradiente de Prewitt\n",
    "        m_g_x = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])\n",
    "        m_g_y = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "    elif grad_type=='sobel':\n",
    "        # Filtros de gradiente de Sobel\n",
    "        m_g_x = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "        m_g_y = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    else:\n",
    "        # Tipo de gradiente desconocido\n",
    "        sys.exit(f'Unknown gradient type \\'{grad_type}\\'')\n",
    "\n",
    "    # Aplica los filtros de gradiente a la imagen\n",
    "    imx = apply_filter(im, m_g_x)\n",
    "    imy = apply_filter(im, m_g_y)\n",
    "\n",
    "    # Calcula la magnitud y dirección del gradiente\n",
    "    e = np.sqrt(imx**2 + imy**2)\n",
    "    phi = np.rad2deg(np.arctan2(imy, imx))\n",
    "\n",
    "    # Devuelve la magnitud y dirección del gradiente\n",
    "    return e, phi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def discretize_angles(img):\n",
    "    \"\"\"\n",
    "    Discretiza los ángulos en 9 bin.\n",
    "\n",
    "    :param ndarray img: Imagen de ángulos.\n",
    "\n",
    "    :return:\n",
    "        ndarray img : Imagen de ángulos discretizada.\n",
    "    \"\"\"\n",
    "    img[((-20 <= img) & (img < 0)) | ((0 <= img) & (img < 20))] = 1\n",
    "    img[((-40 <= img) & (img < -20)) | ((20 <= img) & (img < 40))] = 2\n",
    "    img[((-60 <= img) & (img < -40)) | ((40 <= img) & (img < 60))] = 3\n",
    "    img[((-80 <= img) & (img < -60)) | ((60 <= img) & (img < 80))] = 4\n",
    "    img[((-100 <= img) & (img < -80)) | ((80 <= img) & (img < 100))] = 5\n",
    "    img[((-120 <= img) & (img < -100)) | ((100 <= img) & (img < 120))] = 6\n",
    "    img[((-140 <= img) & (img < -120)) | ((120 <= img) & (img < 140))] = 7\n",
    "    img[((-160 <= img) & (img < -140)) | ((140 <= img) & (img < 160))] = 8\n",
    "    img[((-180 <= img) & (img < -160)) | ((160 <= img) & (img <= 180))] = 9\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_image_characteristics_vector_2(img, size, version='v1', M=2, grad_type='prewitt'):\n",
    "    \"\"\"\n",
    "    Calcula un histograma de direcciones de gradiente en una imagen. Solo soprota imagenes en escala de grises\n",
    "\n",
    "    :param ndarray img: Imagen de entrada.\n",
    "    :param int size: Tamaño del lado de la celda.\n",
    "    :param str version: Normalización a aplicar a los histogramas ('v1', 'v2', o 'v3').\n",
    "    :param int M: Tamaño de bloque de celdas en la normalización 'v2' y 'v3'.\n",
    "    :param str grad_type: Tipo de gradiente a utilizar ('prewitt' o 'sobel').\n",
    "\n",
    "    :return:\n",
    "        ndarray characterictics: El vector de caracteristicas.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calcula la magnitud y dirección del gradiente\n",
    "    e, phi = gradient(img, grad_type)\n",
    "\n",
    "    # Discretiza las direcciones del gradiente en 9 bin\n",
    "    phi = discretize_angles(phi)\n",
    "\n",
    "    # Inicializa el histograma\n",
    "    h = np.empty((int(np.ceil(e.shape[0]/size)), int(np.ceil(e.shape[1]/size)), 9))\n",
    "\n",
    "    # Rellena el histograma con valores de gradiente\n",
    "    for i in range(0,e.shape[0],size):\n",
    "        for j in range(0,e.shape[1],size):\n",
    "            h_p = np.zeros(9)\n",
    "            for k in range(1,9+1):\n",
    "                h_p[k-1] = np.sum(e[i:i+size, j:j+size][phi[i:i+size, j:j+size]==k])\n",
    "            h[i//size, j//size,:] = h_p\n",
    "\n",
    "    # Elige el tipo de normalización\n",
    "    # Normaliza solo en función de su propio valor\n",
    "    if version== 'v1':\n",
    "        norm_factor = np.linalg.norm(h, axis=2)[:,:,np.newaxis]\n",
    "        norm_factor[norm_factor==0] = 1 # Evita divisiones entre 0\n",
    "        h /= norm_factor\n",
    "        characterictics = h.reshape((h.shape[0]*h.shape[1]*9,))\n",
    "\n",
    "    # Normaliza por bloques de M celdas\n",
    "    elif version== 'v2':\n",
    "        for i in range(0,h.shape[0]):\n",
    "            for j in range(0,h.shape[1]):\n",
    "                h_p = h[i:min(i+M,h.shape[0]),j:min(j+M,h.shape[1]),:]\n",
    "                norm_factor = np.linalg.norm(h_p)\n",
    "                norm_factor = norm_factor if norm_factor > 0 else 1# Evita divisiones entre 0\n",
    "                h_p /= norm_factor\n",
    "                h[i:min(i+M,h.shape[0]),j:min(j+M,h.shape[1]),:] = h_p\n",
    "        characterictics = h.reshape((h.shape[0]*h.shape[1]*9,))\n",
    "\n",
    "    # Normaliza cada uno por bloques de M celdas\n",
    "    elif version== 'v3':\n",
    "        h_mod = np.empty(0)\n",
    "        for i in range(0,h.shape[0]-M+1):\n",
    "            for j in range(0,h.shape[1]-M+1):\n",
    "                h_p = h[i:min(i+M,h.shape[0]),j:min(j+M,h.shape[1]),:]\n",
    "                norm_factor = np.linalg.norm(h_p)\n",
    "                norm_factor = norm_factor if norm_factor > 0 else 1# Evita divisiones entre 0\n",
    "                h_p /= norm_factor\n",
    "                h_mod = np.concatenate((h_mod, h_p.flatten()),axis=0)\n",
    "        characterictics = h_mod\n",
    "\n",
    "    else:\n",
    "        sys.exit(f'Unknown normalization type \\'{version}\\'')\n",
    "\n",
    "    return characterictics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <a name=\"S1P3\"></a>3. Funciones adicionales para estandarizar el número de celdas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_size_combinations(S):\n",
    "    \"\"\"\n",
    "    Calcula todas las combinaciones posibles de dos tamaños (nxm) que formen el tamaño total dado.\n",
    "    También calcula las proporciones de cada uno de estos tamaños.\n",
    "\n",
    "    :param int S: El número de celdas deseadas.\n",
    "\n",
    "    :return:\n",
    "        np.ndarray possible_ns: El array con todos los posibles valores de número de celdas en vertical.\n",
    "        np.ndarray possible_ns: El array con todos los posibles valores de número de celdas en horizontal.\n",
    "        np.ndarray proportions: El array con las proporciones entre celdas verticales y horizontales (n:m)\n",
    "        para el tamaño dado. Sigue el orden de possible_ns.\n",
    "    \"\"\"\n",
    "    possible_ns = []\n",
    "    # Recorrer todos los números desde 1 hasta la mitad del tamaño total (a pratir de ahi se repite en orden inverso)\n",
    "    for n in range(1,S//2+1):\n",
    "        # Si el tamaño total es divisible por n, añadir n a la lista de posibles tamaños\n",
    "        if S%n==0:\n",
    "            possible_ns.append(n)\n",
    "    # Calcular las proporciones de cada tamaño utilizando el tamaño al cuadrado dividido por el tamaño total\n",
    "    proportions = np.square(np.array(possible_ns))/S\n",
    "    possible_ns = np.array(possible_ns)\n",
    "    possible_ms = np.int8(possible_ns/proportions)\n",
    "\n",
    "    # Devolver una tupla con los tamaños y las proporciones\n",
    "    return possible_ns, possible_ms, proportions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_image_cell_size(img, props, ns, ms):\n",
    "    \"\"\"\n",
    "    Obtiene el tamaño de celda y proporcion de celdas que mejor se ajusten a la imagen dada y al número de celdas en las que\n",
    "    queremos dividirla.\n",
    "\n",
    "    :param ndarray img: Imagen de entrada.\n",
    "    :param ndarray props: Proporciones posibles para el tamaño y el número de celdas.\n",
    "    :param ndarray ns: Números de celdas en vertical dependiendo de la proporción.\n",
    "    :param ndarray ms: Números de celdas en horizontal dependiendo de la proporción.\n",
    "\n",
    "    :return:\n",
    "        size (int): Tamaño del lado de la celda cuadrada óptima para la imagen.\n",
    "        correction_info (dict): Un diccionario con la información necesaria para poder tratar la imagen conforme al tamaño\n",
    "        que se le haya identificado como óptimo.\n",
    "            d_x y cf_x indican el numero de pixeles a eliminar verticalmente (2*d_x+cf_x)\n",
    "            d_y y cf_y indican el numero de pixeles a eliminar horizontalmente (2*d_y+cf_y)\n",
    "            n y m son el numero de celdas en vetical y horizontal en las que se divide la imagen, resectivamente\n",
    "            p es la proporcion elegida, viene dada por n:m\n",
    "    \"\"\"\n",
    "    p = img.shape[0]/img.shape[1]\n",
    "    indx = np.argmin(np.abs(props-p))\n",
    "\n",
    "    size1 = img.shape[0]//ns[indx]\n",
    "    size2 = img.shape[1]//ms[indx]\n",
    "\n",
    "    size = min(size1, size2)\n",
    "\n",
    "    d_x = int(img.shape[0]/2-size*(ns[indx]/2))\n",
    "    cf_x = 1\n",
    "    if (img.shape[0]/2-size*(ns[indx]/2)).is_integer():\n",
    "        cf_x = 0\n",
    "\n",
    "    d_y = int(img.shape[1]/2-size*(ms[indx]/2))\n",
    "    cf_y = 1\n",
    "    if (img.shape[1]/2-size*(ms[indx]/2)).is_integer():\n",
    "        cf_y = 0\n",
    "\n",
    "    correction_info = {\n",
    "        'd_x':d_x,\n",
    "        'cf_x':cf_x,\n",
    "        'd_y':d_y,\n",
    "        'cf_y':cf_y,\n",
    "        'n':ns[indx],\n",
    "        'm':ms[indx],\n",
    "        'p':props[indx]\n",
    "    }\n",
    "    return size, correction_info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <a name=\"S1P4\"></a>4. Funciones de operación del dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def extract_characteristics(dataset, sizes, extraction_model='base', version='v1', M=2, grad_type='prewitt'):\n",
    "    \"\"\"\n",
    "    Tranforma un conjunto de imagenes en un vector de caracteristicas siguiendo el extraction_model.\n",
    "\n",
    "    :param list dataset: Lista con las imagenes de las que se quiere extraer sus vectores de características.\n",
    "    :param ndarray sizes: Lista de tamaños de celda para cada imagen del dataset.\n",
    "    :param str extraction_model: Tipo de extraccion de caracteristicas a aplicar. Puede ser base o grad.\n",
    "    :param str version: Version del metodo de extraccion.\n",
    "    :param int M: Para el modelo grad y version 2 o 3 se puede suminsitrar un tamaño de bloque de normalizacion.\n",
    "    :param str grad_type: Para el modelo grad ('prewitt' o 'sobel').\n",
    "\n",
    "    :return:\n",
    "        ndarray X: Matriz de vectores de caracteristicas del dataset de tamaño NxM donde N es el número de ejemplos y el tamaño del vector de caracteristicas.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    # Iterar sobre cada imagen en el dataset\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        # Obtener la imagen y el tamaño de la celda\n",
    "        image = dataset[i]\n",
    "        size = sizes[i]\n",
    "\n",
    "        # Extrae el vector de caracteristicas de la imagen\n",
    "        if extraction_model == 'base':\n",
    "            v_caracteristics = get_image_characteristics_vector_1(image, size, version=version)\n",
    "        elif extraction_model == 'grad':\n",
    "            v_caracteristics = get_image_characteristics_vector_2(image, size, version=version, M=M, grad_type=grad_type)\n",
    "        else:\n",
    "            sys.exit(f'Unknown version \\'{version}\\'')\n",
    "        X.append(v_caracteristics)\n",
    "\n",
    "    # TRATAMIENTO DE VECTORES ERRONEOS\n",
    "    shape_counts = Counter([x.shape for x in X])\n",
    "    reference_shape = shape_counts.most_common(1)[0][0]\n",
    "\n",
    "    print(f\"tamaño de referencia: {reference_shape}\")\n",
    "\n",
    "\n",
    "    aux_X = []\n",
    "    for i, vector in enumerate(X[:]):\n",
    "        if vector.shape == reference_shape:\n",
    "            aux_X.append(vector)\n",
    "        else:\n",
    "            print(f'descarte :{i} con tamaño: {vector.shape}')\n",
    "\n",
    "    print(f'tamaño de dataset {len(X)} -> {len(aux_X)}')\n",
    "\n",
    "    # Convertir la lista de vectores de caracteristicas en un array de NumPy\n",
    "    X = np.array(aux_X)\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def standarize_dataset(input_directory, N, colorized=True, clear_output=False):\n",
    "    \"\"\"\n",
    "    Estandariza un conjunto de imágenes de entrada para que se puedan dividir en un mismo numero de celdas.\n",
    "\n",
    "    :param str input_directory: Directorio de entrada con las imágenes.\n",
    "    :param int N: Número de celdas deseado.\n",
    "    :param bool colorized: Indica si se quiere mantener las imagenes a color.\n",
    "    :param bool clear_output: Indica si se quiere vaciar el directorio de salida si existe.\n",
    "\n",
    "    :return:\n",
    "        output_directory (str): Directorio de salida con las imágenes modificadas y los txt con su informacion\n",
    "    \"\"\"\n",
    "    # Se obtienen las posibles combinaciones nxm tal que el total de celdas sea N\n",
    "    ns, ms, proportions = get_size_combinations(N)\n",
    "\n",
    "    # Creacion de un directorio de salida si no existe, si existe error\n",
    "    output_directory = input_directory+'_crop_size_'+str(N) if colorized else input_directory+'_grayscale_crop_size_'+str(N)\n",
    "\n",
    "    if os.path.exists(output_directory):\n",
    "        if clear_output:\n",
    "            shutil.rmtree(output_directory)\n",
    "            os.makedirs(output_directory)\n",
    "        else:\n",
    "            sys.exit(f'Directory already exists \\'{output_directory}\\'')\n",
    "    else:\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "\n",
    "    # Itera sobre los archivos en el directorio\n",
    "    for filename in tqdm(os.listdir(input_directory)):\n",
    "        # Comprueba si se trata de JPG\n",
    "        if not filename.endswith(\".jpg\"):\n",
    "            continue\n",
    "\n",
    "        # Lectura y tratamiento de la imagen\n",
    "        image = imageio.imread(os.path.join(input_directory, filename))\n",
    "        if not colorized:\n",
    "            image = rgb2gray(image)\n",
    "            image = (image*255).astype(np.uint8)\n",
    "\n",
    "        # Recorte de la imagen al tamaño determinado por el tamaño de celda elegido\n",
    "        # Se elimina de ambos lados para que la imagen quede centrada\n",
    "        size, c_info=get_image_cell_size(image, proportions, ns, ms)\n",
    "        image = image[c_info['d_x']:image.shape[0]-c_info['d_x']-c_info['cf_x'],\n",
    "                      c_info['d_y']:image.shape[1]-c_info['d_y']-c_info['cf_y']]\n",
    "\n",
    "        # Guardado de la imagen tratada en el nuevo directorio\n",
    "        imageio.imwrite(os.path.join(output_directory, filename), image)\n",
    "\n",
    "        # Creacion de archivo txt con los datos de la imagen\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        with open(os.path.join(output_directory, base_name + \".txt\"), \"w\") as f:\n",
    "            f.write(f\"image={filename}\\nN={N}\\np={c_info['p']}\\nn={c_info['n']}\\nm={c_info['m']}\\nsize={size}\\n\")\n",
    "\n",
    "    return output_directory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def load_dataset(input_directory):\n",
    "    \"\"\"\n",
    "    Carga un conjunto de imagenes localizado en input_directory y sus tamaños almacenados en el fichero asociado.\n",
    "\n",
    "    :param str input_directory: Directorio de entrada con las imágenes.\n",
    "\n",
    "    :return:\n",
    "        list data: Vector que contiene las imagenes cargadas del directorio.\n",
    "        ndarray sizes: Lista de tamaños de celda calculados para cada imagen del dataset, en el mismo orden.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    sizes = []\n",
    "\n",
    "    # Iterar sobre los archivos en el directorio de entrada\n",
    "    for filename in tqdm(os.listdir(input_directory)):\n",
    "        # Verificar si el archivo es JPG\n",
    "        if not filename.endswith(\".jpg\"):\n",
    "            continue\n",
    "        # Lectura de la imagen\n",
    "        image = imageio.imread(os.path.join(input_directory, filename))\n",
    "\n",
    "        # Abrir el archivo txt con la informacion en modo lectura\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        with open(os.path.join(input_directory, base_name + \".txt\"), \"r\") as f:\n",
    "            # Leer todas las líneas del archivo en una lista\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Iterar sobre las líneas del archivo en orden inverso\n",
    "        for line in reversed(lines):\n",
    "            # Verificar si la línea comienza con \"size=\"\n",
    "            if line.startswith(\"size=\"):\n",
    "                # Extraer el valor después de \"size=\" y asignarlo a la variable size\n",
    "                size = int(line.split(\"=\")[1])\n",
    "                break\n",
    "\n",
    "        data.append(image)\n",
    "        sizes.append(size)\n",
    "\n",
    "    data = data\n",
    "    sizes = np.array(sizes)\n",
    "\n",
    "    return data, sizes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def load_combine_datasets(n=100, n_cells=84):\n",
    "    \"\"\"\n",
    "    Carga y combina los datos de entrenamiento y prueba para perros y gatos.\n",
    "\n",
    "    :param int n: Número de imágenes a cargar.\n",
    "    :param int n_cells: Número de celdas a utilizar para el tamaño de recorte de las imágenes.\n",
    "\n",
    "    :return:\n",
    "        dict data: Diccionario con los datos de entrenamiento y prueba para perros y gatos en escala de grises y a color.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Loading datasets({n})')\n",
    "\n",
    "    data1_dog_train, sizes1_dog_train = load_dataset(f'cat_dog_{n}/train/dog_crop_size_{n_cells}')\n",
    "    data1_cat_train, sizes1_cat_train = load_dataset(f'cat_dog_{n}/train/cat_crop_size_{n_cells}')\n",
    "    data1_dog_test, size1_dog_test = load_dataset(f'cat_dog_{n}/test/dog_crop_size_{n_cells}')\n",
    "    data1_cat_test, size1_cat_test = load_dataset(f'cat_dog_{n}/test/cat_crop_size_{n_cells}')\n",
    "\n",
    "    data2_dog_train, sizes2_dog_train = load_dataset(f'cat_dog_{n}/train/dog_grayscale_crop_size_{n_cells}')\n",
    "    data2_cat_train, sizes2_cat_train = load_dataset(f'cat_dog_{n}/train/cat_grayscale_crop_size_{n_cells}')\n",
    "    data2_dog_test, size2_dog_test = load_dataset(f'cat_dog_{n}/test/dog_grayscale_crop_size_{n_cells}')\n",
    "    data2_cat_test, size2_cat_test = load_dataset(f'cat_dog_{n}/test/cat_grayscale_crop_size_{n_cells}')\n",
    "\n",
    "    data = {\n",
    "        'color':{\n",
    "            'train':{\n",
    "                'cat':{\n",
    "                    'data':data1_cat_train,\n",
    "                    'sizes':sizes1_cat_train\n",
    "                    },\n",
    "                'dog':{\n",
    "                    'data':data1_dog_train,\n",
    "                    'sizes':sizes1_dog_train\n",
    "                    }\n",
    "                },\n",
    "            'test':{\n",
    "                'cat':{\n",
    "                    'data':data1_cat_test,\n",
    "                    'sizes':size1_cat_test\n",
    "                    },\n",
    "                'dog':{\n",
    "                    'data':data1_dog_test,\n",
    "                    'sizes':size1_dog_test\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        'grayscale':{\n",
    "            'train':{\n",
    "                'cat':{\n",
    "                    'data':data2_cat_train,\n",
    "                    'sizes':sizes2_cat_train\n",
    "                    },\n",
    "                'dog':{\n",
    "                    'data':data2_dog_train,\n",
    "                    'sizes':sizes2_dog_train\n",
    "                    }\n",
    "                },\n",
    "            'test':{\n",
    "                'cat':{\n",
    "                    'data':data2_cat_test,\n",
    "                    'sizes':size2_cat_test\n",
    "                    },\n",
    "                'dog':{\n",
    "                    'data':data2_dog_test,\n",
    "                    'sizes':size2_dog_test\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "    }\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def extract_combine_datasets(data, colorized=True, extraction_model='base', version='v1', M=2, grad_type='prewitt'):\n",
    "    \"\"\"\n",
    "    Combina los datos de entrenamiento y prueba para perros y gatos.\n",
    "\n",
    "    :param dict data: Diccionario con los datos de entrenamiento y prueba para perros y gatos en escala de grises o a color.\n",
    "    :param bool colorized: Booleano que indica si se deben extraer las características de los datos a color o en escala de grises.\n",
    "    :param str extraction_model: Modelo de extracción a utilizar para la extracción de características.\n",
    "    :param str version: Versión del modelo de extracción a utilizar.\n",
    "    :param int M: Para el modelo grad y version 2 o 3 se puede suminsitrar un tamaño de bloque de normalizacion.\n",
    "    :param str grad_type: Para el modelo grad ('prewitt' o 'sobel').\n",
    "\n",
    "    :return:\n",
    "        ndarray X, y, Xtest, ytest: Cuatro arrays NumPy con los datos de entrenamiento y prueba para perros y gatos.\n",
    "    \"\"\"\n",
    "\n",
    "    if colorized:\n",
    "        if extraction_model=='grad':\n",
    "            sys.exit(f'Incompatible extraction model \\'{extraction_model}\\' for colorized images')\n",
    "\n",
    "        print('Extracting characteristics (colored)')\n",
    "        X_dog_train = extract_characteristics(data['color']['train']['dog']['data'], data['color']['train']['dog']['sizes'],\n",
    "                                              extraction_model=extraction_model, version=version, M=M, grad_type=grad_type)\n",
    "        y_dog_train = np.zeros(np.array(X_dog_train).shape[0])\n",
    "\n",
    "        X_cat_train = extract_characteristics(data['color']['train']['cat']['data'], data['color']['train']['cat']['sizes'],\n",
    "                                              extraction_model=extraction_model, version=version, M=M, grad_type=grad_type)\n",
    "        y_cat_train = np.ones(np.array(X_cat_train).shape[0])\n",
    "\n",
    "        X_dog_test = extract_characteristics(data['color']['test']['dog']['data'], data['color']['test']['dog']['sizes'],\n",
    "                                             extraction_model=extraction_model, version=version, M=M, grad_type=grad_type)\n",
    "        y_dog_test = np.zeros(np.array(X_dog_test).shape[0])\n",
    "\n",
    "        X_cat_test = extract_characteristics(data['color']['test']['cat']['data'], data['color']['test']['cat']['sizes'],\n",
    "                                             extraction_model=extraction_model, version=version, M=M, grad_type=grad_type)\n",
    "        y_cat_test = np.ones(np.array(X_cat_test).shape[0])\n",
    "\n",
    "    elif not colorized:\n",
    "        print('Extracting characteristics (grayscale)')\n",
    "\n",
    "        X_cat_train = extract_characteristics(data['grayscale']['train']['cat']['data'], data['grayscale']['train']['cat']['sizes'],\n",
    "                                              extraction_model=extraction_model, version=version, M=M, grad_type=grad_type)\n",
    "        y_cat_train = np.ones(np.array(X_cat_train).shape[0])\n",
    "\n",
    "        X_dog_train = extract_characteristics(data['grayscale']['train']['dog']['data'], data['grayscale']['train']['dog']['sizes'],\n",
    "                                              extraction_model=extraction_model, version=version, M=M, grad_type=grad_type)\n",
    "        y_dog_train = np.zeros(np.array(X_dog_train).shape[0])\n",
    "\n",
    "\n",
    "\n",
    "        X_dog_test = extract_characteristics(data['grayscale']['test']['dog']['data'], data['grayscale']['test']['dog']['sizes'],\n",
    "                                             extraction_model=extraction_model, version=version, M=M, grad_type=grad_type)\n",
    "        y_dog_test = np.zeros(np.array(X_dog_test).shape[0])\n",
    "\n",
    "        X_cat_test = extract_characteristics(data['grayscale']['test']['cat']['data'], data['grayscale']['test']['cat']['sizes'],\n",
    "                                             extraction_model=extraction_model, version=version, M=M, grad_type=grad_type)\n",
    "        y_cat_test = np.ones(np.array(X_cat_test).shape[0])\n",
    "\n",
    "    X = np.vstack((X_dog_train, X_cat_train))\n",
    "    y = np.hstack((y_dog_train, y_cat_train)).T\n",
    "\n",
    "    Xtest = np.vstack((X_dog_test, X_cat_test))\n",
    "    ytest = np.hstack((y_dog_test, y_cat_test)).T\n",
    "\n",
    "    # Alterar orden\n",
    "    perm = np.random.permutation(X.shape[0])\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "\n",
    "    perm = np.random.permutation(Xtest.shape[0])\n",
    "    Xtest = Xtest[perm]\n",
    "    ytest = ytest[perm]\n",
    "\n",
    "    return X, y, Xtest, ytest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <a name=\"S1P5\"></a>5. Funciones de almacenamiento y carga de vectores de características de los datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def save_extracted_characteristics(X, y, Xtrain, ytrain, folder_name, override = True):\n",
    "    \"\"\"\n",
    "    Guarda los datos de ejemplos y etiquetas en archivos CSV en la carpeta especificada.\n",
    "\n",
    "    :param ndarray X: Array NumPy con los datos de ejemplos.\n",
    "    :param ndarray y: Array NumPy con las etiquetas de los ejemplos.\n",
    "    :param ndarray Xtrain: Array NumPy con los datos de ejemplos de entrenamiento.\n",
    "    :param ndarray ytrain: Array NumPy con las etiquetas de entrenamiento de los ejemplos.\n",
    "    :param str folder_name: Nombre de la carpeta donde se deben guardar los archivos.\n",
    "    :param bool override: Booleano que indica si se deben sobrescribir los archivos si ya existen.\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_name):\n",
    "        if override:\n",
    "            shutil.rmtree(folder_name)\n",
    "            os.makedirs(folder_name)\n",
    "        else:\n",
    "            sys.exit(f'Directory already exists \\'{folder_name}\\'')\n",
    "    else:\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    # Guardar datos en csv\n",
    "    np.savetxt(os.path.join(folder_name, 'X.csv'), X, delimiter=',')\n",
    "    np.savetxt(os.path.join(folder_name, 'y.csv'), y, delimiter=',')\n",
    "    np.savetxt(os.path.join(folder_name, 'Xtrain.csv'), Xtrain, delimiter=',')\n",
    "    np.savetxt(os.path.join(folder_name, 'ytrain.csv'), ytrain, delimiter=',')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def load_extracted_characteristics(folder_name):\n",
    "    \"\"\"\n",
    "    Carga los datos de ejemplos y etiquetas de archivos CSV de la carpeta especificada.\n",
    "\n",
    "    :param str folder_name: Nombre de la carpeta donde se encuentran los archivos.\n",
    "    :return:\n",
    "        ndarray X, y, Xtrain, ytrain: Cuatro arrays NumPy con los datos de ejemplos y etiquetas cargados.\n",
    "    \"\"\"\n",
    "    X = np.loadtxt(f'{folder_name}/X.csv', delimiter=',')\n",
    "    y = np.loadtxt(f'{folder_name}/y.csv', delimiter=',')\n",
    "    Xtrain = np.loadtxt(f'{folder_name}/Xtrain.csv', delimiter=',')\n",
    "    ytrain = np.loadtxt(f'{folder_name}/ytrain.csv', delimiter=',')\n",
    "\n",
    "    return X, y, Xtrain, ytrain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <a name=\"S2\"></a>Seccion 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <a name=\"S2P1\"></a>1. Tratado previo de imagenes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "n_cells = 84 # Número de celdas en las que se desea dividir las imágenes\n",
    "n = 100 # dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 106.83it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 70.17it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.77it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 91.74it/s]\n",
      "100%|██████████| 500/500 [00:04<00:00, 106.44it/s]\n",
      "100%|██████████| 500/500 [00:05<00:00, 97.34it/s] \n",
      "100%|██████████| 500/500 [00:04<00:00, 102.56it/s]\n",
      "100%|██████████| 500/500 [00:05<00:00, 87.19it/s]\n"
     ]
    }
   ],
   "source": [
    "directories=[f\"cat_dog_{n}/test/cat\",\n",
    "           f\"cat_dog_{n}/test/dog\",\n",
    "           f\"cat_dog_{n}/train/cat\",\n",
    "           f\"cat_dog_{n}/train/dog\"]\n",
    "\n",
    "for directory in directories:\n",
    "    standarize_dataset(directory, n_cells, colorized=True, clear_output=True)\n",
    "    standarize_dataset(directory, n_cells, colorized=False, clear_output=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <a name=\"S2P2\"></a>2. Cargado de los datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets(500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 206.57it/s]\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 220.34it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 202.60it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 186.85it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 257.26it/s]\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 233.06it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 227.04it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 214.10it/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_combine_datasets(n=n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <a name=\"S2P3\"></a>3. Extraccion de carateristicas y almacenamiento de datos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Posibles valores a combinar\n",
    "colorized_values = [True, False]\n",
    "extraction_model_values = ['base', 'grad']\n",
    "version_values = ['v1', 'v2', 'v3']\n",
    "M_values = [2, 4, 6]\n",
    "grad_type_values = ['prewitt', 'sobel']\n",
    "\n",
    "input_combinations = itertools.product(colorized_values, extraction_model_values, version_values, M_values, grad_type_values)\n",
    "\n",
    "# Iteramos sobres las posibles combinaciones\n",
    "for inputs in tqdm(input_combinations, position=1, leave=False):\n",
    "    colorized, extraction_model, version, M, grad_type = inputs\n",
    "\n",
    "    # Omintimos combinaciones no compatibles\n",
    "    if colorized and extraction_model == 'grad':\n",
    "        continue\n",
    "    if extraction_model == 'base' and version == 'v3':\n",
    "        continue\n",
    "    if extraction_model == 'grad' and version != 'v2' and version != 'v3' and M != 2:\n",
    "        continue\n",
    "    if extraction_model == 'base' and (M != 2 or grad_type != 'prewitt'):\n",
    "        continue\n",
    "\n",
    "    # Extraemos los vectores de caracteristicas de los datasets\n",
    "    color = 'color' if colorized else 'grayscale'\n",
    "\n",
    "    # El nombre del directorio contiene el valor de los parametros de la iteración en la que se ha ejecutado.\n",
    "    # Aunque algunos de ellos puedan llegar a no usarse en el proceso de extraccion, semantienen en el nombre para mantener un estandar.\n",
    "    print(f'Treating data:{color}_{extraction_model}_{version}_{M}_{grad_type}')\n",
    "    X, y, Xtest, ytest = extract_combine_datasets(data, colorized, extraction_model, version, M, grad_type)\n",
    "    save_extracted_characteristics(X, y, Xtest, ytest, f'{n_cells}/{color}_{extraction_model}_{version}_{M}_{grad_type}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <a name=\"S3\"></a>Sección 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <a name=\"S3P1\"></a>1. Declaracion de funciones para manejo de clasificadores"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [01:03<00:32,  1.09s/it]"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def LogisticRegression_test(X, y, Xtest, ytest):\n",
    "    \"\"\"\n",
    "    Carga los datos de ejemplos y etiquetas y realiza una prueba de regresión logística utilizando validación cruzada y búsqueda de rejilla.\n",
    "\n",
    "    :param ndarray X: Array NumPy con los datos de ejemplos para entrenamiento.\n",
    "    :param ndarray y: Array NumPy con las etiquetas de los ejemplos de entrenamiento.\n",
    "    :param ndarray Xtest: Array NumPy con los datos de ejemplos para pruebas.\n",
    "    :param ndarray ytest: Array NumPy con las etiquetas de los ejemplos de pruebas.\n",
    "    :return:\n",
    "    tuple best_params, accTrain, accTest: Tupla con el mejor conjunto de parámetros encontrado, el porcentaje de acierto en el conjunto de entrenamiento y el porcentaje de acierto en el conjunto de pruebas, respectivamente.\n",
    "    \"\"\"\n",
    "    # Se incializa el modelo llamando al constructor de la regresión lineal: todos los parámetros se asignan a los valores mencionados anteriormente\n",
    "    LogReg = LogisticRegression()\n",
    "\n",
    "    # Set up cross-validation with ShuffleSplit and grid search with GridSearchCV\n",
    "    rs = ShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "    param_grid = {'C': [1], 'max_iter': [200, 300, 400], 'solver': ['newton-cg', 'lbfgs']}#NOTA: 'liblinear', 'sag' (best of 10) eliminados C100 eliminado (best of 10) C10 eliminado(best of 7)\n",
    "    clf = GridSearchCV(LogReg, param_grid, n_jobs=-1, cv=rs)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Get the best estimator\n",
    "    best_estimator = clf.best_estimator_\n",
    "\n",
    "    # Cálculo del porcentaje de acierto (recuerda no pasar la columna de 1's)\n",
    "    pred_train = best_estimator.predict(X)\n",
    "    pred_test = best_estimator.predict(Xtest)\n",
    "    accTrain = metrics.accuracy_score(pred_train, y)\n",
    "    accTest = metrics.accuracy_score(pred_test, ytest)\n",
    "\n",
    "    best_params = clf.best_params_\n",
    "\n",
    "    return best_params, accTrain, accTest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def MultinomialNB_test(X, y, Xtest, ytest):\n",
    "    \"\"\"\n",
    "    Carga los datos de ejemplos y etiquetas y realiza una prueba de clasificacion por naive bayes utilizando validación cruzada y búsqueda de rejilla.\n",
    "\n",
    "    :param ndarray X: Array NumPy con los datos de ejemplos para entrenamiento.\n",
    "    :param ndarray y: Array NumPy con las etiquetas de los ejemplos de entrenamiento.\n",
    "    :param ndarray Xtest: Array NumPy con los datos de ejemplos para pruebas.\n",
    "    :param ndarray ytest: Array NumPy con las etiquetas de los ejemplos de pruebas.\n",
    "    :return:\n",
    "    tuple best_params, accTrain, accTest: Tupla con el mejor conjunto de parámetros encontrado, el porcentaje de acierto en el conjunto de entrenamiento y el porcentaje de acierto en el conjunto de pruebas, respectivamente.\n",
    "    \"\"\"\n",
    "    # Configurar validación cruzada con ShuffleSplit y búsqueda con GridSearchCV\n",
    "    rs = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    param_grid = {'alpha': [1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "    clf = GridSearchCV(MultinomialNB(), param_grid, cv=rs)\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Obtener el mejor estimador\n",
    "    best_estimator = clf.best_estimator_\n",
    "\n",
    "    # Obtener predicciones\n",
    "    pred_train = best_estimator.predict(X)\n",
    "    pred_test = best_estimator.predict(Xtest)\n",
    "\n",
    "    # Calcular precisión\n",
    "    accTrain = metrics.accuracy_score(pred_train, y)\n",
    "    accTest = metrics.accuracy_score(pred_test, ytest)\n",
    "    best_params = clf.best_params_\n",
    "    return best_params, accTrain, accTest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def MLPClassifier_test(X, y, Xtest, ytest):\n",
    "    \"\"\"\n",
    "    Carga los datos de ejemplos y etiquetas y realiza una prueba de clasificador mlp utilizando validación cruzada y búsqueda de rejilla.\n",
    "\n",
    "    :param ndarray X: Array NumPy con los datos de ejemplos para entrenamiento.\n",
    "    :param ndarray y: Array NumPy con las etiquetas de los ejemplos de entrenamiento.\n",
    "    :param ndarray Xtest: Array NumPy con los datos de ejemplos para pruebas.\n",
    "    :param ndarray ytest: Array NumPy con las etiquetas de los ejemplos de pruebas.\n",
    "    :return:\n",
    "    tuple best_params, accTrain, accTest: Tupla con el mejor conjunto de parámetros encontrado, el porcentaje de acierto en el conjunto de entrenamiento y el porcentaje de acierto en el conjunto de pruebas, respectivamente.\n",
    "    \"\"\"\n",
    "    # Configurar validación cruzada con ShuffleSplit y búsqueda de grilla con GridSearchCV\n",
    "    rs = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    param_grid = {'hidden_layer_sizes': [10, 15, 20], 'max_iter': [200, 250, 300], 'solver': ['lbfgs']}\n",
    "    clf = GridSearchCV(MLPClassifier(), param_grid, cv=rs)\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Obtener el mejor estimador\n",
    "    best_estimator = clf.best_estimator_\n",
    "\n",
    "    # Obtener predicciones\n",
    "    pred_train = best_estimator.predict(X)\n",
    "    pred_test = best_estimator.predict(Xtest)\n",
    "\n",
    "    # Calcular precisión\n",
    "    accTrain = metrics.accuracy_score(pred_train, y)\n",
    "    accTest = metrics.accuracy_score(pred_test, ytest)\n",
    "    best_params = clf.best_params_\n",
    "\n",
    "    return  best_params, accTrain, accTest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def SVC_test(X, y, Xtest, ytest):\n",
    "    \"\"\"\n",
    "    Carga los datos de ejemplos y etiquetas y realiza una prueba de clasificador svc utilizando validación cruzada y búsqueda de rejilla.\n",
    "\n",
    "    :param ndarray X: Array NumPy con los datos de ejemplos para entrenamiento.\n",
    "    :param ndarray y: Array NumPy con las etiquetas de los ejemplos de entrenamiento.\n",
    "    :param ndarray Xtest: Array NumPy con los datos de ejemplos para pruebas.\n",
    "    :param ndarray ytest: Array NumPy con las etiquetas de los ejemplos de pruebas.\n",
    "    :return:\n",
    "    tuple best_params, accTrain, accTest: Tupla con el mejor conjunto de parámetros encontrado, el porcentaje de acierto en el conjunto de entrenamiento y el porcentaje de acierto en el conjunto de pruebas, respectivamente.\n",
    "    \"\"\"\n",
    "    # Configurar validación cruzada con ShuffleSplit y búsqueda de grilla con GridSearchCV\n",
    "    rs = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    param_grid = {'C': [0.01, 0.03, 0.1, 0.3, 1, 3], 'gamma': [0.01, 0.03, 0.1, 0.3, 1, 3]}\n",
    "    clf = GridSearchCV(svm.SVC(), param_grid, n_jobs=-1, cv=rs)\n",
    "\n",
    "    # Ajustar el modelo a los datos\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Obtener el mejor estimador\n",
    "    best_estimator = clf.best_estimator_\n",
    "\n",
    "    # Obtener predicciones\n",
    "    pred_train = best_estimator.predict(X)\n",
    "    pred_test = best_estimator.predict(Xtest)\n",
    "\n",
    "    # Calcular la precisión\n",
    "    accTrain = metrics.accuracy_score(pred_train, y)\n",
    "    accTest = metrics.accuracy_score(pred_test, ytest)\n",
    "\n",
    "    best_params = clf.best_params_\n",
    "\n",
    "    return best_params, accTrain, accTest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def RandomForest_test(X, y, Xtest, ytest):\n",
    "    \"\"\"\n",
    "    Carga los datos de ejemplos y etiquetas y realiza una prueba de clasificador encemble de random forest utilizando validación cruzada y búsqueda de rejilla.\n",
    "\n",
    "    :param ndarray X: Array NumPy con los datos de ejemplos para entrenamiento.\n",
    "    :param ndarray y: Array NumPy con las etiquetas de los ejemplos de entrenamiento.\n",
    "    :param ndarray Xtest: Array NumPy con los datos de ejemplos para pruebas.\n",
    "    :param ndarray ytest: Array NumPy con las etiquetas de los ejemplos de pruebas.\n",
    "    :return:\n",
    "    tuple best_params, accTrain, accTest: Tupla con el mejor conjunto de parámetros encontrado, el porcentaje de acierto en el conjunto de entrenamiento y el porcentaje de acierto en el conjunto de pruebas, respectivamente.\n",
    "    \"\"\"\n",
    "    # Set up cross-validation with ShuffleSplit and grid search with GridSearchCV\n",
    "    rs = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    param_grid = {'n_estimators': [10, 50, 100, 200],\n",
    "                  'max_depth': [5, 10, 15],\n",
    "                  'max_features': ['log2', 'sqrt'],\n",
    "                  'criterion': ['entropy', 'gini']}\n",
    "    clf = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=-1, cv=rs)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Get the best estimator\n",
    "    best_estimator = clf.best_estimator_\n",
    "\n",
    "    # Obtain predictions\n",
    "    pred_train = best_estimator.predict(X)\n",
    "    pred_test = best_estimator.predict(Xtest)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accTrain = metrics.accuracy_score(pred_train, y)\n",
    "    accTest = metrics.accuracy_score(pred_test, ytest)\n",
    "\n",
    "    best_params = clf.best_params_\n",
    "\n",
    "    return best_params, accTrain, accTest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <a name=\"S3P2\"></a>2. Prueba de parametros"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]C:\\Users\\ivons\\miniconda3\\envs\\py38ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 44%|████▍     | 8/18 [13:30<07:47, 46.79s/it]   C:\\Users\\ivons\\miniconda3\\envs\\py38ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 56%|█████▌    | 10/18 [14:09<04:18, 32.28s/it]C:\\Users\\ivons\\miniconda3\\envs\\py38ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 83%|████████▎ | 15/18 [16:18<01:30, 30.17s/it]C:\\Users\\ivons\\miniconda3\\envs\\py38ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "100%|██████████| 18/18 [18:35<00:00, 61.99s/it]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "n_cells = 84 # Número de celdas en las que se desea dividir las imágenes\n",
    "n = 100 # dataset\n",
    "\n",
    "# Posibles valores a combinar\n",
    "colorized_values = [True, False]\n",
    "extraction_model_values = ['base', 'grad']\n",
    "version_values = ['v1', 'v2', 'v3']\n",
    "M_values = [2, 4, 6]\n",
    "grad_type_values = ['prewitt', 'sobel']\n",
    "\n",
    "# Generamos las posibles combinaciones de parametros\n",
    "param_combinations = list(product(colorized_values, extraction_model_values, version_values, M_values, grad_type_values))\n",
    "\n",
    "#Filtramos casos\n",
    "filtered_param_combinations=[]\n",
    "for colorized, extraction_model, version, M, grad_type in param_combinations:\n",
    "    # Omitimos combinaciones no compatibles\n",
    "    if colorized and extraction_model == 'grad':\n",
    "        continue\n",
    "    if extraction_model == 'base' and version == 'v3':\n",
    "        continue\n",
    "    if extraction_model == 'grad' and version != 'v2' and version != 'v3' and M != 2:\n",
    "        continue\n",
    "    if extraction_model == 'base' and (M != 2 or grad_type != 'prewitt'):\n",
    "        continue\n",
    "    filtered_param_combinations.append((colorized, extraction_model, version, M, grad_type))\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Iteramos sobre las combinaciones\n",
    "for colorized, extraction_model, version, M, grad_type in tqdm(filtered_param_combinations,leave=True):\n",
    "\n",
    "    color = 'color' if colorized else 'grayscale'\n",
    "\n",
    "    # Cargamos los datos para esta combinacion en particular\n",
    "    X, y, Xtest, ytest = load_extracted_characteristics(f'{n_cells}/{color}_{extraction_model}_{version}_{M}_{grad_type}')\n",
    "\n",
    "\n",
    "    params, accTrain, accTest = LogisticRegression_test(X, y, Xtest, ytest)\n",
    "\n",
    "    results[(color, extraction_model, version, M, grad_type, 'LogisticRegression')] = (params, accTrain, accTest)\n",
    "\n",
    "\n",
    "    params, accTrain, accTest = MultinomialNB_test(X, y, Xtest, ytest)\n",
    "\n",
    "    results[(color, extraction_model, version, M, grad_type, 'MultinomialNB')] = (params, accTrain, accTest)\n",
    "\n",
    "\n",
    "    params, accTrain, accTest = MLPClassifier_test(X, y, Xtest, ytest)\n",
    "\n",
    "    results[(color, extraction_model, version, M, grad_type, 'MLPClassifier')] = (params, accTrain, accTest)\n",
    "\n",
    "\n",
    "    params, accTrain, accTest = SVC_test(X, y, Xtest, ytest)\n",
    "\n",
    "    results[(color, extraction_model, version, M, grad_type, 'SVC')] = (params, accTrain, accTest)\n",
    "\n",
    "\n",
    "    params, accTrain, accTest = RandomForest_test(X, y, Xtest, ytest)\n",
    "\n",
    "    results[(color, extraction_model, version, M, grad_type, 'RandomForest')] = (params, accTrain, accTest)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination of parameters: ('color', 'base', 'v1', 2, 'prewitt', 'SVC')\n",
      "Best test accuracy: 1.0\n",
      "1. Combination of parameters: ('color', 'base', 'v1', 2, 'prewitt', 'SVC'): {'C': 0.01, 'gamma': 0.01}, trainAcc:1.0, testAcc:1.0\n",
      "2. Combination of parameters: ('color', 'base', 'v2', 2, 'prewitt', 'SVC'): {'C': 0.01, 'gamma': 0.01}, trainAcc:1.0, testAcc:1.0\n",
      "3. Combination of parameters: ('grayscale', 'base', 'v1', 2, 'prewitt', 'SVC'): {'C': 0.01, 'gamma': 0.01}, trainAcc:1.0, testAcc:1.0\n",
      "4. Combination of parameters: ('grayscale', 'base', 'v2', 2, 'prewitt', 'SVC'): {'C': 0.01, 'gamma': 0.01}, trainAcc:1.0, testAcc:1.0\n",
      "5. Combination of parameters: ('grayscale', 'grad', 'v3', 6, 'prewitt', 'SVC'): {'C': 3, 'gamma': 1}, trainAcc:1.0, testAcc:0.95\n",
      "6. Combination of parameters: ('grayscale', 'grad', 'v3', 2, 'sobel', 'RandomForest'): {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 100}, trainAcc:0.995, testAcc:0.925\n",
      "7. Combination of parameters: ('color', 'base', 'v2', 2, 'prewitt', 'LogisticRegression'): {'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}, trainAcc:1.0, testAcc:0.9\n",
      "8. Combination of parameters: ('grayscale', 'base', 'v1', 2, 'prewitt', 'MLPClassifier'): {'hidden_layer_sizes': 15, 'max_iter': 200, 'solver': 'lbfgs'}, trainAcc:1.0, testAcc:0.9\n",
      "9. Combination of parameters: ('grayscale', 'grad', 'v2', 2, 'sobel', 'RandomForest'): {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}, trainAcc:0.98, testAcc:0.9\n",
      "10. Combination of parameters: ('grayscale', 'grad', 'v2', 4, 'sobel', 'SVC'): {'C': 1, 'gamma': 3}, trainAcc:0.995, testAcc:0.9\n",
      "11. Combination of parameters: ('grayscale', 'grad', 'v3', 6, 'prewitt', 'MLPClassifier'): {'hidden_layer_sizes': 15, 'max_iter': 250, 'solver': 'lbfgs'}, trainAcc:1.0, testAcc:0.9\n",
      "12. Combination of parameters: ('grayscale', 'grad', 'v3', 6, 'sobel', 'LogisticRegression'): {'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}, trainAcc:0.945, testAcc:0.9\n",
      "13. Combination of parameters: ('grayscale', 'grad', 'v3', 6, 'sobel', 'MLPClassifier'): {'hidden_layer_sizes': 15, 'max_iter': 250, 'solver': 'lbfgs'}, trainAcc:1.0, testAcc:0.9\n",
      "14. Combination of parameters: ('color', 'base', 'v1', 2, 'prewitt', 'LogisticRegression'): {'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}, trainAcc:1.0, testAcc:0.875\n",
      "15. Combination of parameters: ('grayscale', 'base', 'v1', 2, 'prewitt', 'LogisticRegression'): {'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}, trainAcc:1.0, testAcc:0.875\n",
      "16. Combination of parameters: ('grayscale', 'base', 'v2', 2, 'prewitt', 'LogisticRegression'): {'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}, trainAcc:1.0, testAcc:0.875\n",
      "17. Combination of parameters: ('grayscale', 'grad', 'v2', 4, 'prewitt', 'SVC'): {'C': 1, 'gamma': 3}, trainAcc:0.995, testAcc:0.875\n",
      "18. Combination of parameters: ('grayscale', 'grad', 'v3', 2, 'prewitt', 'RandomForest'): {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 200}, trainAcc:1.0, testAcc:0.875\n",
      "19. Combination of parameters: ('grayscale', 'grad', 'v3', 2, 'sobel', 'SVC'): {'C': 1, 'gamma': 0.1}, trainAcc:1.0, testAcc:0.875\n",
      "20. Combination of parameters: ('grayscale', 'grad', 'v3', 4, 'sobel', 'RandomForest'): {'criterion': 'entropy', 'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 50}, trainAcc:1.0, testAcc:0.875\n"
     ]
    }
   ],
   "source": [
    "best_params = max(results, key=lambda x: results[x][-1])\n",
    "best_accuracy = results[best_params]\n",
    "print(f\"Best combination of parameters: {best_params}\")\n",
    "print(f\"Best test accuracy: {best_accuracy[-1]}\")\n",
    "\n",
    "top_n = 20\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1][-1], reverse=True)[:top_n]\n",
    "\n",
    "for i, (params, (model_params, train_acc, test_acc)) in enumerate(sorted_results):\n",
    "    print(f\"{i+1}. Combination of parameters: {params}: {model_params}, trainAcc:{train_acc}, testAcc:{test_acc}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ('color', 'base', 'v1', 2, 'prewitt', 'SVC'):{'C': 0.01, 'gamma': 0.01}\n",
      "2 ('color', 'base', 'v2', 2, 'prewitt', 'SVC'):{'C': 0.01, 'gamma': 0.01}\n",
      "3 ('grayscale', 'base', 'v1', 2, 'prewitt', 'SVC'):{'C': 0.01, 'gamma': 0.01}\n",
      "4 ('grayscale', 'base', 'v2', 2, 'prewitt', 'SVC'):{'C': 0.01, 'gamma': 0.01}\n",
      "5 ('grayscale', 'grad', 'v3', 6, 'prewitt', 'SVC'):{'C': 3, 'gamma': 1}\n",
      "6 ('grayscale', 'grad', 'v3', 2, 'sobel', 'RandomForest'):{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 100}\n",
      "7 ('color', 'base', 'v2', 2, 'prewitt', 'LogisticRegression'):{'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}\n",
      "8 ('grayscale', 'base', 'v1', 2, 'prewitt', 'MLPClassifier'):{'hidden_layer_sizes': 15, 'max_iter': 200, 'solver': 'lbfgs'}\n",
      "9 ('grayscale', 'grad', 'v2', 2, 'sobel', 'RandomForest'):{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "10 ('grayscale', 'grad', 'v2', 4, 'sobel', 'SVC'):{'C': 1, 'gamma': 3}\n",
      "11 ('grayscale', 'grad', 'v3', 6, 'prewitt', 'MLPClassifier'):{'hidden_layer_sizes': 15, 'max_iter': 250, 'solver': 'lbfgs'}\n",
      "12 ('grayscale', 'grad', 'v3', 6, 'sobel', 'LogisticRegression'):{'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}\n",
      "13 ('grayscale', 'grad', 'v3', 6, 'sobel', 'MLPClassifier'):{'hidden_layer_sizes': 15, 'max_iter': 250, 'solver': 'lbfgs'}\n",
      "14 ('color', 'base', 'v1', 2, 'prewitt', 'LogisticRegression'):{'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}\n",
      "15 ('grayscale', 'base', 'v1', 2, 'prewitt', 'LogisticRegression'):{'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}\n",
      "16 ('grayscale', 'base', 'v2', 2, 'prewitt', 'LogisticRegression'):{'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}\n",
      "17 ('grayscale', 'grad', 'v2', 4, 'prewitt', 'SVC'):{'C': 1, 'gamma': 3}\n",
      "18 ('grayscale', 'grad', 'v3', 2, 'prewitt', 'RandomForest'):{'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "19 ('grayscale', 'grad', 'v3', 2, 'sobel', 'SVC'):{'C': 1, 'gamma': 0.1}\n",
      "20 ('grayscale', 'grad', 'v3', 4, 'sobel', 'RandomForest'):{'criterion': 'entropy', 'max_depth': 15, 'max_features': 'sqrt', 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort the dictionary by test accuracy\n",
    "sorted_dict = dict(sorted(results.items(), key=lambda x: x[1][2], reverse=True))\n",
    "\n",
    "# Get the top n entries\n",
    "n = 20\n",
    "top_n = dict(list(sorted_dict.items())[:n])\n",
    "\n",
    "# Extract the numeric values from the keys\n",
    "x_values = list(range(1,n+1))\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bar_width = 0.35\n",
    "ax.bar(x_values, [x[2] for x in top_n.values()], width=bar_width, label='Test Accuracy')\n",
    "ax.bar([x+bar_width for x in x_values], [x[1] for x in top_n.values()], width=bar_width, label='Train Accuracy')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# Add the grid\n",
    "ax.grid(linestyle='-.', which='major', axis='y', alpha=0.8, linewidth=0.5)\n",
    "ax.grid(which='minor', linestyle='-.', alpha=0.8)\n",
    "\n",
    "# Add the parameters as text labels\n",
    "names=[]\n",
    "for i, key in enumerate(top_n.keys()):\n",
    "    names.append(f'{key}:{top_n[key][0]}')\n",
    "\n",
    "ax.set_xticks(x_values)\n",
    "\n",
    "plt.show()\n",
    "for i, word in enumerate(names):\n",
    "    print(i+1, word)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### <a name=\"S3P3\"></a>3. Prueba final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraccion con:('grayscale', 'grad', 'v3', 6, 'prewitt')\n",
      "Loading datasets(500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 594.02it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 290.37it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 340.39it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 280.92it/s]\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 440.81it/s]\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 359.87it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 406.03it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 410.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting characteristics (grayscale)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [08:12<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño de referencia: (4536,)\n",
      "descarte :61 con tamaño: (2916,)\n",
      "descarte :99 con tamaño: (2916,)\n",
      "descarte :205 con tamaño: (2916,)\n",
      "descarte :218 con tamaño: (2916,)\n",
      "descarte :229 con tamaño: (2916,)\n",
      "descarte :362 con tamaño: (2916,)\n",
      "descarte :426 con tamaño: (2916,)\n",
      "tamaño de dataset 500 -> 493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [08:55<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño de referencia: (4536,)\n",
      "descarte :199 con tamaño: (2916,)\n",
      "descarte :249 con tamaño: (2916,)\n",
      "descarte :292 con tamaño: (2916,)\n",
      "descarte :313 con tamaño: (2916,)\n",
      "tamaño de dataset 500 -> 496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:46<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño de referencia: (4536,)\n",
      "tamaño de dataset 100 -> 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:35<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño de referencia: (4536,)\n",
      "tamaño de dataset 100 -> 100\n",
      "Clasificacion con SVC con parametros: {'C': 3, 'gamma': 1}\n",
      "Precisión en Train: 1.0\n",
      "Precisión en Test: 0.94\n"
     ]
    }
   ],
   "source": [
    "n_cells = 84\n",
    "n = 500\n",
    "configuracion = 4 # Elegimos una de las configuraciones observadas en la lista anterior 'sorted_results'\n",
    "\n",
    "(params, (model_params, train_acc, test_acc)) = sorted_results[configuracion]\n",
    "\n",
    "colorized = True if params[0]=='color' else False\n",
    "extraction_model = params[1]\n",
    "version = params[2]\n",
    "M = params[3]\n",
    "grad_type = params[4]\n",
    "\n",
    "print(f'Extraccion con:{params[:-1]}')\n",
    "\n",
    "X, y, Xtest, ytest = extract_combine_datasets(load_combine_datasets(n=n, n_cells=n_cells), colorized=colorized,\n",
    "                                              extraction_model=extraction_model, version=version, M=M, grad_type=grad_type)\n",
    "\n",
    "classiffier = params[5]\n",
    "\n",
    "if classiffier == 'LogisticRegression':\n",
    "    print(f'Clasificacion con LogisticRegression con parametros: {model_params}')\n",
    "    LogReg = LogisticRegression(C=model_params['C'], max_iter=model_params['max_iter'], solver=model_params['solver'])\n",
    "    LogReg.fit(X, y)\n",
    "    pred_train = LogReg.predict(X)\n",
    "    pred_test = LogReg.predict(Xtest)\n",
    "    accTrain = metrics.accuracy_score(pred_train, y)\n",
    "    accTest = metrics.accuracy_score(pred_test, ytest)\n",
    "\n",
    "    print(f'Precisión en Train: {accTrain}')\n",
    "    print(f'Precisión en Test: {accTest}')\n",
    "\n",
    "\n",
    "elif classiffier == 'MultinomialNB':\n",
    "    print(f'Clasificacion con MultinomialNB con parametros: {model_params}')\n",
    "    MultiNB = MultinomialNB(alpha=model_params['alpha'])\n",
    "    MultiNB.fit(X, y)\n",
    "    pred_train = MultiNB.predict(X)\n",
    "    pred_test = MultiNB.predict(Xtest)\n",
    "    accTrain = metrics.accuracy_score(pred_train, y)\n",
    "    accTest = metrics.accuracy_score(pred_test, ytest)\n",
    "\n",
    "    print(f'Precisión en Train: {accTrain}')\n",
    "    print(f'Precisión en Test: {accTest}')\n",
    "\n",
    "elif classiffier == 'MLPClassifier':\n",
    "    print(f'Clasificacion con MLPClassifier con parametros: {model_params}')\n",
    "    MLPClass = MLPClassifier(hidden_layer_sizes=model_params['hidden_layer_sizes'], max_iter=model_params['max_iter'], solver=model_params['solver'])\n",
    "    MLPClass.fit(X, y)\n",
    "    pred_train = MLPClass.predict(X)\n",
    "    pred_test = MLPClass.predict(Xtest)\n",
    "    accTrain = metrics.accuracy_score(pred_train, y)\n",
    "    accTest = metrics.accuracy_score(pred_test, ytest)\n",
    "\n",
    "    print(f'Precisión en Train: {accTrain}')\n",
    "    print(f'Precisión en Test: {accTest}')\n",
    "\n",
    "elif classiffier == 'SVC':\n",
    "    print(f'Clasificacion con SVC con parametros: {model_params}')\n",
    "    SVC = svm.SVC(C=model_params['C'], gamma=model_params['gamma'])\n",
    "    SVC.fit(X, y)\n",
    "    pred_train = SVC.predict(X)\n",
    "    pred_test = SVC.predict(Xtest)\n",
    "    accTrain = metrics.accuracy_score(pred_train, y)\n",
    "    accTest = metrics.accuracy_score(pred_test, ytest)\n",
    "\n",
    "    print(f'Precisión en Train: {accTrain}')\n",
    "    print(f'Precisión en Test: {accTest}')\n",
    "\n",
    "elif classiffier == 'RandomForestClassifier':\n",
    "    print(f'Clasificacion con RandomForestClassifier con parametros: {model_params}')\n",
    "    RaFoCla = RandomForestClassifier(n_estimators=model_params['n_estimators'], max_depth=model_params['max_depth'],\n",
    "                                     max_features=model_params['max_features'],criterion=model_params['criterion'])\n",
    "    RaFoCla.fit(X, y)\n",
    "    pred_train = RaFoCla.predict(X)\n",
    "    pred_test = RaFoCla.predict(Xtest)\n",
    "    accTrain = metrics.accuracy_score(pred_train, y)\n",
    "    accTest = metrics.accuracy_score(pred_test, ytest)\n",
    "\n",
    "    print(f'Precisión en Train: {accTrain}')\n",
    "    print(f'Precisión en Test: {accTest}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
